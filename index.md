---
layout: home
title: Home
---

We release data collected in the rugged Scottish highlands in extreme weather.
The radar data we offer to the community are accompanied by GPS/INS reference - to further stimulate research in radar place recognition

# Data

We release data from four areas of the Ardverikie Estate.
These feature distinct landscape (therefore typical radar returns) as well as driving conditions.
In total we drive a diverse set of four routes over 11 forays, totalling approximately 154km of rugged driving.

Please follow the (radar, gps) links below to download the data.

<style>
table td {
    border: none;
    padding: 10px;
    padding-top: 0px;
    vertical-align: top;
}
table {
    border: none;
}
table tr:nth-child(even) {
  background: transparent;
}
</style>

<table cellspacing="0" cellpadding="0" style="margin-top: 30px;">
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<tbody>
<tr>
<td markdown="span" style="text-align: center; vertical-align: middle;">**Bellmouth** </td>
<td markdown="span" style="text-align: center; vertical-align: middle;">**Hydro** </td>
</tr>
<tr>
<td markdown="span">![]({{ site.baseurl }}/images/gps/bellmouth.png)</td>
<td markdown="span">![]({{ site.baseurl }}/images/gps/hydro.png)</td>
</tr>
<tr>
<td markdown="span">**2021-11-25-12-01-20** (<a href="https://drive.google.com/file/d/1jf7d5lKf_1COPbdYWAEY3MKOPJHnGbgz/view?usp=drive_link" class="myButton">radar</a>, <a href="https://drive.google.com/file/d/1rc30WPf_hY-XVQjiroJaNwtBwgexI2zf/view?usp=drive_link" class="myButton">gps</a>)</td>
<td markdown="span">**2021-11-27-14-37-20** (<a href="https://drive.google.com/file/d/1biPCuPh-0jUfVPGTu3PWZkgi6e01vNga/view?usp=drive_link" class="myButton">radar</a>, <a href="https://drive.google.com/file/d/14_2mfIx3JdRORTjag-XPwes8uT2gd1eC/view?usp=drive_link" class="myButton">gps</a>)</td>
</tr>
<tr>
<td markdown="span">**2021-11-25-12-31-19** (<a href="https://drive.google.com/file/d/1N1ORMyMT5ngY3DyAs27uh8T5nhf_lljA/view?usp=drive_link" class="myButton">radar</a>, <a href="https://drive.google.com/file/d/1NPXdN9gpjTslj0W5avv6B_P2Lvc4hXjd/view?usp=drive_link" class="myButton">gps</a>)</td>
<td markdown="span">**2021-11-27-15-24-02** (<a href="https://drive.google.com/file/d/1-dILLlwuML3XGJu--0G3k98l07Sl5XQr/view?usp=drive_link" class="myButton">radar</a>, <a href="https://drive.google.com/file/d/1vjTm7WcufV5i6XF15tWbNdwgquVwbnJc/view?usp=drive_link" class="myButton">gps</a>)</td>
</tr>
<tr>
<td markdown="span">**2021-11-26-15-35-34** (<a href="https://drive.google.com/file/d/1CKdHE8pAsGNk_MN0bsin0uwPmt0mRwGS/view?usp=drive_link" class="myButton">radar</a>, <a href="https://drive.google.com/file/d/1qa5BPKxwuXILQvjfflvj5iJOQyZxD5GM/view?usp=drive_link" class="myButton">gps</a>)</td>
<td markdown="span">**2021-11-27-16-03-26** (<a href="https://drive.google.com/file/d/1lv_pQ3BwBUDioe7Ba1wFH42sT2xQfK0-/view?usp=drive_link" class="myButton">radar</a>, <a href="https://drive.google.com/file/d/10q7epenKeW5Epo5rnm3HEyK1r60gQ8DZ/view?usp=drive_link" class="myButton">gps</a>)</td>
</tr>
<tr>
<td markdown="span">**2021-11-26-16-12-01** (<a href="https://drive.google.com/file/d/13go4Y3cI0lt0w_n2F_CnBUQQ74ygtRKO/view?usp=drive_link" class="myButton">radar</a>, <a href="https://drive.google.com/file/d/1Ufq-uju9GNY6OM_nzLQt2grByQIjemKe/view?usp=drive_link" class="myButton">gps</a>)</td>
</tr>
<tr>
<td markdown="span" style="text-align: center; vertical-align: middle;">**Maree** </td>
<td markdown="span" style="text-align: center; vertical-align: middle;">**Two Lochs** </td>
</tr>
<tr>
<td markdown="span">![]({{ site.baseurl }}/images/gps/maree.png)</td>
<td markdown="span">![]({{ site.baseurl }}/images/gps/twolochs.png)</td>
</tr>
<tr>
<td markdown="span">**2021-11-28-15-54-55** (<a href="https://drive.google.com/file/d/1BMgE_mpJyleZv8fkZNuXIh2slK3TrJu8/view?usp=drive_link" class="myButton">radar</a>, <a href="https://drive.google.com/file/d/1qOkBzEALOQmuSpI7MnmQ0ptys7N6p09V/view?usp=drive_link" class="myButton">gps</a>)</td>
<td markdown="span">**2021-11-29-11-40-37** (<a href="https://drive.google.com/file/d/1qwbL9A0beH8tD3s-5ewTUFVruV0hST7r/view?usp=drive_link" class="myButton">radar</a>, <a href="https://drive.google.com/file/d/1n57ibUX728LVqrkQXeTHvo03Itg7NFQg/view?usp=drive_link" class="myButton">gps</a>)</td>
</tr>
<tr>
<td markdown="span">**2021-11-28-16-43-37** (<a href="https://drive.google.com/file/d/1qeVkZ6mBYIXUjs65VWPMDDSdBxqcGx0s/view?usp=drive_link" class="myButton">radar</a>, <a href="https://drive.google.com/file/d/14Gj831Lp5bv8jRb1rV1eIXSCHCo1HY05/view?usp=drive_link" class="myButton">gps</a>)</td>
<td markdown="span">**2021-11-29-12-19-16** (<a href="https://drive.google.com/file/d/1JDX_QcsAd7E3KB1DCng_W0OfEWgK5Emu/view?usp=drive_link" class="myButton">radar</a>, <a href="https://drive.google.com/file/d/1jZ773gVZnkgcc4HCFmPi0twI9QKL-OpA/view?usp=drive_link" class="myButton">gps</a>)</td>
</tr>
</tbody>
</table>

# Software Development Kit

A software development kit is available at [https://github.com/mttgdd/oord-dataset](https://github.com/mttgdd/oord-dataset).
This allows quick setup of place recognition experiments and ground truth performance evaluation, as below.

We start by specifying the configuration of our experiment in `config/alexnet.yaml`.

```yaml
tar_dir: /Volumes/saxdata2/data
out_dir: /home/mattgadd/experiments/oord/test
data_dir: /home/mattgadd/data/oord

seed: 42
batch_size: 16
device: cuda:0
downsample: 5
pos_gps: 25.0
neg_gps: 50.0

min_bin: 60
max_bin: 3768
cartesian: True
cart_res: 1.2717
cart_pw: 224
channels: 3
fft: False

gps_match_tolerance: 25.0
```

We then write a simple wrapper `jobs/test_alexnet.py` around a common test routine in `src/test.py`

```python
from config.config import get_cfg_impl
from src.test import test

import torch

cfg = get_cfg_impl('config/pretrained_networks.yaml')

net = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)
net.eval()

test(cfg, net, None, 'alexnet')
```

Running the job with `python -m jobs.test_alexnet`, the embedding distance matrix are exported as pngs and we can also generate all ground truth matrices as pngs with:

```bash
python -m tex.figs_gps
```

This gives us the following example outputs at `/home/mattgadd/experiments/oord/test/alexnet_2021-11-25-12-31-19_2021-11-25-12-01-20.png` and `/home/mattgadd/experiments/oord/test/2021-11-25-12-31-19_2021-11-25-12-01-20-positives.png`:

<table cellspacing="0" cellpadding="0" style="margin-top: 30px;">
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<tbody>
<tr>
<td markdown="span">![]({{ site.baseurl }}/images/example/diff.png)</td>
<td markdown="span">![]({{ site.baseurl }}/images/example/positives.png)</td>
</tr>
</tbody>
</table>

[comment]: # TODO: get diff png

The recall@n metrics are run as part of the call to `src/test.py` above and are written to e.g. `/home/mattgadd/experiments/oord/test/alexnet_2021-11-25-12-31-19_2021-11-25-12-01-20.csv` with the following example contents.

```text
,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49
0,0.7491190979563073,0.8463706835799859,0.8787878787878788,0.9062720225510923,0.9238900634249472,0.9330514446793516,0.9400986610288936,0.9443269908386187,0.9471458773784355,0.952783650458069,0.959830866807611,0.9626497533474278,0.9640591966173362,0.9654686398872445,0.9704016913319239,0.9760394644115574,0.9774489076814659,0.9795630725863284,0.9802677942212826,0.9809725158562368,0.9830866807610994,0.9830866807610994,0.9859055673009162,0.9859055673009162,0.9859055673009162,0.9866102889358703,0.9880197322057788,0.9880197322057788,0.9880197322057788,0.9894291754756871,0.9894291754756871,0.9894291754756871,0.9908386187455955,0.9908386187455955,0.9908386187455955,0.9908386187455955,0.9908386187455955,0.9908386187455955,0.9915433403805497,0.9915433403805497,0.9915433403805497,0.9922480620155039,0.992952783650458,0.9943622269203665,0.9943622269203665,0.9943622269203665,0.9950669485553206,0.9950669485553206,0.9950669485553206
```

Reading this, we have 74.91% recall@1 for alexnet.

# Trained model checkpoints

For the neural network approaches explored in the paper, we release 4 saved checkpoints at [huggingface.co/mttgdd/oord-models](huggingface.co/mttgdd/oord-models). Example use is as below:

```python
from src.resnet18_netvlad import Net

from huggingface_hub import hf_hub_download
import torch

net = Net()
weights = hf_hub_download(
      repo_id="mttgdd/oord_models", filename="resnet18_netvlad_oord-2021-11-25-12-31-19.pth")
net.load_state_dict(torch.load(weights))
```

# Citation

Please cite the following paper when using the dataset in your research.

**OORD: The Oxford Offroad Radar Dataset** <br>
M. Gadd, D. De Martini, O. Bartlett, P. Murcutt, M. Towlson, M. Widojo, V. Muşat, L. Robinson, E. Panagiotaki, G. Pramatarov, M. A. Kühn, L. Marchegiani, P. Newman, L. Kunze<br>
<i>arXiv preprint arXiv:2403.02845</i>, 2024 <br>
{% include bibtex.html text="
@article{gadd2024oord,
title={{OORD: The Oxford Offroad Radar Dataset}},
author={Gadd, Matthew and De Martini, Daniele and Bartlett, Oliver and Murcutt, Paul and Towlson, Matt and Widojo, Matthew and Mu\cb{s}at, Valentina and Robinson, Luke and Panagiotaki, Efimia and Pramatarov, Georgi and K\"uhn, Marc Alexander and Marchegiani, Letizia and Newman, Paul and Kunze, Lars},
journal={arXiv preprint arXiv:2403.02845},
year={2024}
}
" %}
